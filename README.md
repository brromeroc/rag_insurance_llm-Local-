Bienvenido a rah_insurance_llm, en este repositorio encontrara un agente experto en el documento que se le suministe, esta hecho en python con un modelo local llamado llama3.2 (3B parameters, 2 GB)
el cual puede obtener descargando ollama (https://ollama.com/search) y  luego yendo a su cmd y colocando ollama run llama3.2.

Para instalar las dependencias que utiliza el agente utilice pip install -r requirements.txt.

Para ejecutarlo solomante abra una terminal cmd en la carpeta donde se encuentre rag_insurance_llm.py, y escriba streamlit run rag_insurance_llm.py

Si quiere interacturar con el agente sin instalar nada, puede ingresar al siguiente link: https://bizrate-proxy-money-hats.trycloudflare.com/
